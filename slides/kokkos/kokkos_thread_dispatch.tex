%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (1)}

  \begin{itemize}
  \item \textbf{3 types of parallel dispatch}
    \begin{itemize}
    \item \texttt{Kokkos::parallel\_for}
    \item \texttt{Kokkos::parallel\_reduce}
    \item \texttt{Kokkos::parallel\_scan}
    \end{itemize}
  \item A dispatch needs as input
    \begin{itemize}
    \item \textcolor{red}{\textbf{an execution policy:}} e.g. a range (can simply be an integer), team of threads, ...
    \item \textbf{a body:} specified as a lambda function or a functor
    \end{itemize}
  \item Very important: launching a kernel (thread dispatching) is by default asynchronous
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (2)}

  {\large \textcolor{violet}{How to specify a compute kernel in Kokkos ?}}
  \begin{enumerate}
  \item \textcolor{blue}{\textbf{Use Lambda functions.}}\\
    NB: a lambda in c++11 is an unnamed function object capable of capturing variables in scope.
    \begin{minted}{c++}
      Kokkos::parallel_for (100, KOKKOS_LAMBDA (const int i) {
        data(i) = 2*i;
      });
    \end{minted}
    \textbf{Here we do 2 things in 1 step: define the computation body (lambda func) and launch computation.}
  \item \textcolor{darkgreen}{\textbf{Use a C++ functor class.}}\\
    A functor is a class containing a function to execute in parallel.
    {\small
      \begin{minted}{c++}
        class FunctorType {
          public:
          KOKKOS_INLINE_FUNCTION
          void operator() ( const int i ) const ;
        };
        ...
        FunctorType func;
        Kokkos::parallel_for (100, func);
      \end{minted}
    }
    \textbf{Note: 100 here is the simplest way to specify an execution policy}
  \end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (3)}

  {\Large \textcolor{violet}{Notes on macros defined in \texttt{core/src/Kokkos\_Macros.hpp}}}

  \begin{itemize}
  \item \textcolor{blue}{\texttt{KOKKOS\_LAMBA}} is a macro which provides a compiler-portable way of specifying a lambda function with \textbf{capture-by-value closure}.
    \begin{itemize}
    \item \textcolor{blue}{\texttt{KOKKOS\_LAMBA}} must be used at the most outer parallel loop; inside a lambda one can all another lambda
    \end{itemize}
  \item \textcolor{darkgreen}{\texttt{KOKKOS\_INLINE\_FUNCTION}} \texttt{void operator() (...) const;}\\
    this macro helps providing the necessary compiler specific \textit{decorators}, e.g. \texttt{\_\_device\_\_} for Cuda to make sure the body can be turns into a Cuda kernel.
    \begin{itemize}
    \item macro \textcolor{darkgreen}{\texttt{KOKKOS\_INLINE\_FUNCTION}} must be applied to any function call inside a parallel loop
    \end{itemize}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (4)}


  \textbf{Lambda or Functor: which one to use in Kokkos ? Both !}
  \begin{enumerate}
  \item \textcolor{blue}{\textbf{Use Lambda functions.}}\\
    \begin{itemize}
    \item easy way for small compute kernels
    \item For GPU, requires Cuda 7.5 (8.0 is current and latest CUDA version)
    \end{itemize}
  \item \textcolor{darkgreen}{\textbf{Use a C++ functor class.}}\\
    \begin{itemize}
    \item More flexible, allow to design more complex kernel
    \end{itemize}
  \end{enumerate}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (5)}

  {\large \textcolor{violet}{\textbf{About Kokkos::parallel\_reduce with lambda}}}

  \begin{itemize}
  \item As for \texttt{parallel\_for}, loop body can be specified as a lambda, or a functor; here is the lambda way when reduce operation is \texttt{sum}:
  \end{itemize}
  {\small
    \begin{minted}{c++}
      Kokkos::parallel_reduce (100, KOKKOS_LAMBDA (const int i, int &local_sum) {
        local_sum += data(i);
      }, sum);
    \end{minted}
  }
  
\end{frame}
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (6)}

  {\large \textcolor{violet}{\textbf{About Kokkos::parallel\_reduce functor}}}

  \begin{itemize}
  \item Kokkos supplies a default \texttt{init} / \texttt{join} operator which is \texttt{operator+}
  \item If the reduce operator is not trivial (i.e. not a sum) $\Rightarrow$ you need to define methods \texttt{init} and \texttt{join}
  \end{itemize}

  {\small
    \begin{minted}{c++}
      class ReduceFunctor {
        public:
        // declare a constructor ...
        KOKKOS_INLINE_FUNCTION void 
        operator() (const int i, data_t &update) const {...}

        // How to join/combine intermediate reduce from different threads
        KOKKOS_INLINE_FUNCTION void 
        join(volatile data_t &dst, const volatile data_t &src) const {...}

        // how each thread initializes its reduce result
        KOKKOS_INLINE_FUNCTION void 
        init(const volatile data_t &dst) const {...}
      }
      \end{minted}
    }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (7)}
  
  {\Large \textcolor{violet}{\textbf{Parallel dispatch - execution policy}}}

  \begin{itemize}
  \item Remember that an execution policy specifies \textbf{how} a parallel dispatch is done by the device
  \item \textcolor{darkgreen}{\bf Range policy:} from...to\\
    no prescription of order of execution nor concurrency; allows to adapt to the actual hardware; e.g. a GPU has some level of hardware parallelism (Streaming Multiprocessor) and some levels of concurrency (warps and block of threads).
  \item \textcolor{orange}{\bf Multidimensional range:} still experimental (as of January 2017), mapping a higher than 1D range of iteration.
  \end{itemize}
  {\small
    \begin{minted}{c++}
      // create the MDrangePolicy object
      using namespace Kokkos::Experimental;
      using range_type = MDRangePolicy< Rank<2>, Kokkos::IndexType<int> >;
      range_type range( {0,0}, {N0,N1} );
      
      // use a special multidimensional parallel for launcher
      md_parallel_for(range, functor);
    \end{minted}
  }

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (8)}
  
  {\Large \textcolor{violet}{\textbf{Parallel dispatch - execution policy}}}

  \begin{itemize}
  \item \textcolor{blue}{\bf Team policy:} for {\bf hierarchical parallelism}
    \begin{itemize}
    \item threads team %$\Longleftrightarrow$ thread block (in CUDA)
    \item threads inside a team %$\Longleftrightarrow$ thread (in CUDA)
    \item vector lanes
    \end{itemize}
  \item 
    {\small
      \begin{minted}{c++}
        // Using default execution space and launching
        // a league with league_size teams with team_size threads each
        Kokkos::TeamPolicy <>
        policy( league_size , team_size );
      \end{minted}
    }
    equivalent to launching in CUDA a 1D grid of 1D blocks of threads.\\
    Team scratch pad memory $\Longleftrightarrow$ CUDA shared memory
  \end{itemize}
\end{frame}
  
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels - parallel dispatch (9)}
  
  {\Large \textcolor{violet}{\textbf{Hierarchical parallelism (advanced)}}}

  \begin{itemize}
  \item OpenMP: League of Teams of Threads
  \item Cuda: Grid of Blocks of Threads
  \item Experimental features: task parallelism\\
    {\small see slides by C. Edwards at GTC2016 \myhref{https://cfwebprod.sandia.gov/cfdocs/CompResearch/docs/2016-04-GTC-Kokkos-Task.pdf}{2016-04-GTC-Kokkos-Task.pdf}}
  \end{itemize}
  
\end{frame}
