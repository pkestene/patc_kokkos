%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}
  \frametitle{Hands-On 1 : query\_device}

  \begin{itemize}
  \item We will first re-use material from Kokkos github repository.
  \item On your home, on \texttt{ouessant}: 
    \begin{enumerate}
    \item \texttt{mkdir kokkos-tutorial; cd kokkos-tutorial}
    \item \texttt{git clone https://github.com/kokkos/kokkos.git} \\
      \# \textbf{Don't try to build kokkos here (for now)}
    %\item \texttt{git clone https://github.com/kokkos/kokkos-tutorials.git}
    %\item \texttt{cd kokkos-tutorials/1-Day-Tutorial}\\
    %  \# 1 Day tutorial exercice are routed to \textbf{build kokkos for you}
    \end{enumerate}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Hands-On 1 : query\_device}

  {\large\textcolor{red}{\textbf{Purpose:} just cross-checking Kokkos/Hwloc is working OK}}

  \begin{itemize}
  \item Kokkos sources will be built by the application Makefile
  \item \texttt{cd \$HOME/kokkos-tutorial/example/query\_device}
  \item open \texttt{query\_device.cpp}; no computations, it just prints hardware information
  \item 
    \begin{enumerate}
    \item \textbf{Default serial build (with hwloc):} \texttt{make KOKKOS\_USE\_TPLS="hwloc"}\\
      How many NUMA / Cores / Hyperthreads on power8 CPU ?\\
      What is the current SMT mode on a ouessant login node ? (use command \texttt{ppc64\_cpu \--\--smt} or \texttt{ppc64\_cpu --info})
    \item \textbf{OpenMP build (with hwloc):} \texttt{make KOKKOS\_USE\_TPLS="hwloc" KOKKOS\_DEVICES=OpenMP} (off course, exact same information obtained)
    \item \textbf{CUDA/OpenMP build (with hwloc):} \texttt{make KOKKOS\_USE\_TPLS="hwloc" KOKKOS\_DEVICES=Cuda,OpenMP}; rerun and you should get information about the CPU+GPU configuration
    \end{enumerate}
  \item Take some time to have a look at Makefile.\\
    Note that latter when using an installed kokkos library, we won't need to set architecture or device related variables on the command line .
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Hands-On 1 : query\_device}

  {\large\textcolor{red}{\textbf{Purpose:} just cross-checking Kokkos/Hwloc is working OK}}

  \begin{itemize}
  \item \textcolor{orange}{\textbf{What happens if hwloc is not activated ?}}
  \item Edit file \texttt{query\_device.cpp} and do the following modification:
    \begin{enumerate}
    \item Add \texttt{Kokkos::initialize(argc, argv);} after \texttt{MPI\_Init}
    \item Add \texttt{Kokkos::finalize();} before \texttt{MPI\_Finalize}
    \item change\\
      {\small
        \begin{minted}{c++}
          #if defined( KOKKOS_HAVE_CUDA )
            Kokkos::Cuda::print_configuration( msg );
          #else
            Kokkos::OpenMP::print_configuration( msg );
          #endif
        \end{minted}
      }
    \end{enumerate}
  \item {\small Rebuild 1 \textcolor{red}{without HWLOC:} \texttt{make KOKKOS\_DEVICES=OpenMP}}
    {\small
      \begin{minted}{bash}
        Kokkos::OpenMP KOKKOS_HAVE_OPENMP thread_pool_topology[ 1 x 80 x 1 ]
      \end{minted}
    }
  \item {\small Rebuild 2 \textcolor{darkgreen}{with HWLOC:} \texttt{make KOKKOS\_DEVICES=OpenMP KOKKOS\_USE\_TPLS="hwloc"}}
    {\small 
      \begin{minted}{bash}
        hwloc( NUMA[2] x CORE[10] x HT[4] )
        Kokkos::OpenMP KOKKOS_HAVE_OPENMP hwloc[2x10x4] hwloc_binding_enabled thread_pool_topology[ 2 x 10 x 4 ]      
      \end{minted}
    }
    \item As already said: processor affinity is crucial to performance
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Hands-On 2 : SAXPY from 1-Day-Tutorial}

  {\large \textcolor{red}{\textbf{Purpose:}} The simplest computing kernel in Kokkos}

  \begin{itemize}
  %\item \textbf{Proposed activity}
  \item \textcolor{red}{\textbf{Saxpy serial (reference executable on Power8)}}
    \begin{itemize}
    \item \texttt{cd \$HOME/kokkos-tutorial/kokkos-tutorials/1-Day-Tutorial/Exercises/01\_AXPY/Serial}
    \item Open \texttt{Makefile} and change \texttt{SNB} into \texttt{Power8}
    \item \texttt{make}
    \end{itemize}
  \item \textcolor{orange}{\textbf{Saxpy OpenMP (on Power8)}}
    \begin{itemize}
    \item \texttt{cd \$HOME/kokkos-tutorial/kokkos-tutorials/1-Day-Tutorial/Exercises/01\_AXPY/Kokkos-Lambda}
    \item Change again \texttt{Makefile}
    \item Add 3 lines in \texttt{saxpy.cpp} right after Kokkos initialization
      \begin{minted}{c++}
        std::ostringstream msg;
        Kokkos::OpenMP::print_configuration( msg );
        std::cout << msg.str();
      \end{minted}
    \item Make sure all available CPU cores were used ($1\times 160 \times 1$)
    \item Change the number of OpenMP threads created by kokkos, e.g. :\\
      \texttt{./saxpy.host  --threads=20}
    \item We need to change \texttt{Makefile} and use \textcolor{red}{\textbf{hwloc}}\\
      add \texttt{KOKKOS\_USE\_TPLS="hwloc"} right after \texttt{KOKKOS\_DEVICES} in \texttt{Makefile}\\
      Rebuild and rerun, you should see that application uses \textbf{all the available numa domains}, and an increased bandwidth usage !
    \end{itemize}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{SAXPY from 1-Day-Tutorial}

  \begin{itemize}
  \item \textbf{Proposed activity}
  \item \textcolor{darkgreen}{\textbf{Saxpy CUDA (on Power8 + Nvidia K80/P100)}}
    \begin{itemize}
    \item \texttt{cd \$HOME/kokkos-tutorial/kokkos-tutorials/1-Day-Tutorial/Exercises/01\_AXPY/Kokkos-Lambda}
    \item \texttt{module load cuda/8.0}
    \item Change again \texttt{Makefile}: \\
      add CUDA to variable KOKKOS\_DEVICES = "Cuda,OpenMP"\\
      Kepler35 $\Rightarrow$ Kepler37 (for Nvidia K80)\\
      Kepler35 $\Rightarrow$ Pascal60 (for Nvidia P100)
    \end{itemize}
  \item Rebuild for K80, run on ouessant (front node)
  \item Rebuild for P100, run on compute node using \texttt{submit\_ouessant.sh} (should see a strong difference)
  \end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos data Container}

  \begin{itemize}
  \item \texttt{Kokkos::View<...>}; replacement for \texttt{std::vector} with multidimensionnal feature and hardware adapted memory layout\\
    \begin{itemize}
    \item \texttt{Kokkos::View<double **>}
    \end{itemize}

  \item \texttt{Kokkos::DualView<...>} : usefull when porting an application incrementally, adata container on two different memory space.\\
    see \texttt{tutorial/Advanced\_Views/04\_dualviews/dual\_view.cpp}
  \item \texttt{Kokkos::UnorderedMap<...>}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels}

  \begin{itemize}
  \item How to specify a compute kernel in Kokkos ?
    \begin{enumerate}
    \item \textcolor{blue}{\textbf{Use Lambda functions.}}\\
      NB: a lambda in c++11 is an unnamed function object capable of capturing variables in scope.
      \begin{minted}{c++}
        Kokkos::parallel_for (100, KOKKOS_LAMBDA (const int i) {
          data(i) = 2*i;
        });
      \end{minted}
    \item \textcolor{darkgreen}{\textbf{Use a C++ functor class.}}\\
      A functor is a class containing a function to execute in parallel.
      \begin{minted}{c++}
        class FunctorType {
          public:
          KOKKOS_INLINE_FUNCTION
          void operator() ( const int i ) const ;
        };
      \end{minted}
    \end{enumerate}
  \end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile=singleslide]
  \frametitle{Kokkos compute Kernels}

  \textbf{Lambda or Functor: which one to use in Kokkos ? Both !}
  \begin{enumerate}
  \item \textcolor{blue}{\textbf{Use Lambda functions.}}\\
    \begin{itemize}
    \item easy way for small compute kernels
    \item For GPU, requires Cuda 7.5 (8.0 is current and latest CUDA version)
    \end{itemize}
  \item \textcolor{darkgreen}{\textbf{Use a C++ functor class.}}\\
    \begin{itemize}
    \item More flexible, allow to design more complex kernel
    \end{itemize}
  \end{enumerate}
\end{frame}
